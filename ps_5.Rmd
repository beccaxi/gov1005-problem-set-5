---
title: "Problem Set 5"
author: "Rebecca Xi"
date: "3/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(haven)
library(gt)
library(tidyverse)

# Import data from Voter Study Group, survey wave beginning on 12/26/2019

survey <- read_dta("raw-data/ns20191226/ns20191226.dta")
```


## Question #1: Mad Libs

```{r ML1, echo=FALSE}

# To simplify things, I first select the user responses to the gun_registry
# question only. Per the codebook, a value of 888 indicates "Not Asked", so I
# filter out all "Not Asked" responses of 888. count() then counts the number of
# remaining rows for me, i.e. the number or respondents who were actually asked
# the question.

r1 <- survey %>% 
  select(gun_registry) %>%
  filter(gun_registry != 888) %>% 
  count()
```

ML 1) Not all respondents were asked every question. `r r1` respondents were 
asked the question about whether the USA should create a gun registry.


```{r ML2, echo=FALSE}

# Per the codebook, the four policy questions are labeled as guns_bg (background
# checks), gun_registry, ban_guns, and limit_magazines. Since gun_registry is
# the only question that might not have been asked, I filter as before in Mad
# Libs 1. I also select household_gun_owner to set up the next step.

all_four <- survey %>% 
  select(
    guns_bg, 
    gun_registry, 
    ban_guns, 
    limit_magazines, 
    household_gun_owner
  ) %>% 
  filter(gun_registry != 888)

# Per the codebook, a value of 1 in the the column labeled household_gun_owner
# indicates that the respondent is personally a gun owner

gun_owner_count <- all_four %>% 
  filter(household_gun_owner == 1) %>% 
  count()

# After finding the total number of respondents who answered all four questions,
# I divide one count by the other and multiply by 100 to get a percentage value

all_four_count <- all_four %>% 
  count()
r2 <- (100 * gun_owner_count / all_four_count) %>% 
  round(digits = 2)
```

ML 2) Of the respondents that got asked all four gun policy questions, `r r2` 
percent are gun owners. (For the purposes of this question, you can assume that 
the people who answered “not sure” are not gun owners). Round to 2 digits after 
the decimal point.


```{r ML3, echo=FALSE}

# Per the codebook, a value of 3 under household_gun_owner indicates that nobody
# in the household owns a gun. I also want to disregard respondents who weren't
# asked (888), weren't sure (999), or skipped the question (.). After filtering
# for those respondents, I take the mean.

r3_1 <- survey %>% 
  select(household_gun_owner, statements_gun_rights) %>% 
  filter(
    household_gun_owner == 3,
    statements_gun_rights != 888,
    statements_gun_rights != 999,
    statements_gun_rights != "."
  ) %>% 
  summarize(mean(statements_gun_rights)) %>% 
  round(digits = 2)

# For households with guns, I copy paste the previous code chunk but filter for
# values of 1 (I personally own a gun) or 2 (someone in household owns a gun)
# under household_gun_owner

r3_2 <- survey %>% 
  select(household_gun_owner, statements_gun_rights) %>% 
  filter(
    household_gun_owner == 1 | household_gun_owner == 2, 
    statements_gun_rights != 888,
    statements_gun_rights != 999,
    statements_gun_rights != "."
  ) %>% 
  summarize(mean(statements_gun_rights)) %>% 
  round(digits = 2)
```

ML 3) The average “agreement” score (from 1-4) on the statement_gun_rights 
variable is `r r3_1` for those respondents who live in households without guns, 
while the average “agreement” score in households with guns is `r r3_2`. 
(Calculate the average dropping respondents who weren’t asked, didn’t know, or 
skipped either question, and round to two digits after the decimal point).


```{r ML4, echo=FALSE}

# Here I use as_factor to assign the right labels to the different values of the
# religion variable, based on the already existing "labels" viewable in the data

labelled <- survey %>% 
  select(age, religion) %>% 
  as_factor(levels = "labels")

# Here I filter for the age group of people 18-30 and determine which religion
# label has the highest count. I do this using a Mode function which takes in
# factor data and returns the most frequently occurring level of that factor
# (https://stackoverflow.com/questions/2547402/is-there-a-built-in-function-for-
# finding-the-mode).

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

r4_1 <- labelled %>% 
  filter(age >= 18 & age < 30) %>%
  summarize(religion = Mode(religion))
  
# Now, simply repeat for the age group of people 30 and older, using the same
# Mode function

r4_2 <- labelled %>% 
  filter(age >= 30) %>% 
  summarize(religion = Mode(religion))
```

ML 4) Another set of questions asks about religion. The first ranked category of
religion for the age group of people 18-30 (don’t include 30) is “`r r4_1`” . 
The first-ranked religion category for people 30 and older is “`r r4_2`”. Hint: 
you’re going to need the “labels” that are imported from the dta using haven; we 
suggest using as_factor to assign the right labels to the religion variable.


```{r ML5, echo=FALSE}

# This question entails coming up with the frequency table of a factor variable.
# I observe from calling factor(labelled$religion) that there are 13 factor
# levels in total. I isolate the 18-30 age group from the get go and
# additionally filter out any NA values of the religion variable. Next, I create
# the frequency table using the count() function from the plyr package and
# arrange the resulting table in descending order. In order to eventually select
# for the ranking of "nothing in particular" in each age group, I create a new
# column that assigns a ranking number to each level, from 1 onward.

eighteenthirty <- labelled %>% 
  filter(
    age >= 18 & age < 30,
    !is.na(religion)
  ) %>%
  count(religion) %>% 
  arrange(desc(n))
eighteenthirty_ranked <- eighteenthirty %>% 
  mutate(rank = 1:nrow(eighteenthirty))

# Here I filter for the religion level in question ("Nothing in particular") and
# select just the corresponding value from the rank column I created in the
# previous code block

r5_1 <- eighteenthirty_ranked %>% 
  filter(religion == "Nothing in particular") %>% 
  select(rank)

# Here I repeat the above processes for the 30 and above group. The only thing
# that changes, obviously, is the original filter on age.

thirtyup <- labelled %>% 
  filter(
    age >= 30,
    !is.na(religion)
  ) %>% 
  count(religion) %>% 
  arrange(desc(n))
thirtyup_ranked <- thirtyup %>% 
  mutate(rank = 1:nrow(thirtyup))

r5_2 <- thirtyup_ranked %>% 
  filter(religion == "Nothing in particular") %>% 
  select(rank)
```

ML 5) Lots of people say that the younger generation has the highest percent of 
“nones;” people who answer “nothing in particular”, when you ask them their 
religion. In the 18-30 age group, “nothing in particular” is ranked `r r5_1`, 
while in the 30 and above group, “nothing in particular” is ranked `r r5_2`.


```{r ML6, echo=FALSE}

# Starting from scratch with survey, I assign labels to factor levels for
# religion as before and filter for "Nothing in particular", the group of
# interest. I then immediately filtered statements_gun_rights to eliminate those
# respondents that were not asked, were unsure, or skipped the question. Next, I
# create a frequency table for statements_gun_rights using count() as before and
# arrange in descending order before selecting for the most frequently occurring
# response at the top of the table.

r6 <- survey %>%
  as_factor(levels = "labels") %>% 
  filter(
    religion == "Nothing in particular",
    statements_gun_rights != "Not Asked" &
    statements_gun_rights != "Not sure" &
    statements_gun_rights != "Respondent Skipped"
  ) %>%
  select(statements_gun_rights) %>%
  group_by(statements_gun_rights) %>% 
  count() %>%
  arrange(desc(n)) %>% 
  head(1) %>% 
  select(statements_gun_rights)
```

ML 6) Consider again the nones (all people who responded “nothing in 
particular”) when asked about their religion. In this group, the most popular 
position is to `r r6` (strongly disagree, disagree, agree, or strongly agree?) 
that it is more important for the government to control who owns guns than it is
for the government to protect the right to own guns (use the variable “statement_gun_rights” and only include respondents who were asked both of these questions).



## Question #2: Simulations with List Columns

```{r 2A, echo=FALSE}

# This function draws n cards from a deck consisting practically of just
# diamonds, hearts, spades, and clubs (the four suits). The function samples
# without replacement (replace = TRUE) and only works for numeric inputs.

draw_cards <- function(n) {
  stopifnot(is.numeric(n))
  sample(c("diamonds", "hearts", "spades", "clubs"), size = n, replace = TRUE)
}
```

#### 2A)

See RMarkdown file.


```{r 2B, echo=FALSE}

# With identical format as in the "craps" class, I draw 2 cards 10 times and map
# the results in a tibble with 10 rows and one list column

tibble <- tibble(results = map(1:10, ~ draw_cards(2)))
```

#### 2B)

See RMarkdown file.


```{r 2C, echo=FALSE}

# Here I edit the tibble using mutate() and map_lgl() in order to add two new
# columns (1 for each card drawn). Each column entry contains either TRUE or
# FALSE in accordance with the condition defined in ifelse(), i.e. whether the
# card in question is red (a heart or diamond) or not. If TRUE, the card is red;
# if FALSE, the card is black (or not red).

tibble <- tibble %>%  
  mutate(
    red1 = map_lgl(
      results, 
      ~ ifelse(
        .[[1]] == "hearts" |
        .[[1]] == "diamonds",
        TRUE, 
        FALSE)
    ),
    red2 = map_lgl(
      results, 
      ~ ifelse(
        .[[2]] == "hearts" |
        .[[2]] == "diamonds",
        TRUE, 
        FALSE)
    )
  )
```

#### 2C)

See RMarkdown file.


#### 2D)

```{r 2D, echo=FALSE}

# Here I use mutate() and case_when() to add a new column that states whether
# the outcome of each 2-card draw is “both red (two TRUEs), “both black” (two
# FALSEs), or “mixed” (which has two cases, which are the two permutations of
# one TRUE and one FALSE). I decide to call this new column "outcome",
# appropriately.

tibble <- tibble %>% 
  mutate(outcome = case_when(
    red1 == TRUE & red2 == TRUE ~ "Both red",
    red1 == FALSE & red2 == FALSE ~ "Both black",
    red1 == TRUE & red2 == FALSE ~ "mixed",
    red1 == FALSE & red2 == TRUE ~ "mixed"
    )
  )

# Here I create a gt table of the tibble. Using the gt package and with the pset
# instructions as guide, I add a title, subtitle, and relabel the four columns
# accordingly.

table <- tibble %>% 
  gt() %>% 
  tab_header(
      title = "Drawing Two Cards",
      subtitle = "Card Colors"
    ) %>%
    cols_label(
      results = "Draw",
      red1 = "First card red?", 
      red2 = "Second card red?",
      outcome = "Color Outcome"
    )
table
```


```{r 2E, echo=FALSE}

# 


```

#### 2E)

When I simulate drawing two cards 1000 times, __ percent of my cards have 
"mixed" colors.



## Question #3: Modeling a Study Population




## Question #4: Sampling




## Question #5: Sampling and Sample Size




## Question #6: Publish your Plot

[Rpubs link]



## Question #7: Reprex

https://github.com/GOV-1005-Spring-2020/problem-set-5-beccaxi/issues/1



## Question #8: Demonstrating Understanding of Sampling

The population N of the country is constant and, as a running presidential 
candidate with elections coming up fast, I would like to know the proportion of 
the population that (as of right now) would vote for me. A complete census or 
survey of the entire population is impossible given our budget, so I have to 
make do with a sample instead and come up with the most accurate sample 
proportion that I can. 

I have the choice to poll a sample of size n = 5000 from the five major cities 
(1000 from each city), or a sample of equal size n = 5000 from the ten states 
(500 in each state). I would like whichever sample I choose to be a 
representative sample (that is, one that roughly looks like the entire 
population) so that the polls will provide a more accurate depiction of my odds 
of winning the upcoming election. This is basically equivalent to wanting my 
sample proportion to be generalizable to the population. 

Assuming that each of the five major cities contains a decently significant 
proportion of the population of the state in which that city is located, I 
choose to sample 500 people from each of the ten states. By doing so, I ensure 
that I get a representative sample of the states in which none of the major 
cities are located. As for the states that do contain major cities: the 
assumption allows me to assume that the major cities themselves will be well 
represented in the samples of the states in which they are located, making 
perhaps for a "biased" sampling in which individuals that live in the five major 
cities have a higher chance of being included in the sampling of their state's 
population than individuals in other cities and areas within that state. In 
essence, under the terms of the assumption, a sample of 500 individuals from 
each state will be generalizable to the entire population of the ten states 
while likely being skewed toward those who live in the five major cities, 
thereby fulfilling close to the same function as a sample of 1000 people from 
each of those five cities.








